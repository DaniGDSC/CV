{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77baaaf",
   "metadata": {},
   "source": [
    "SIFT + RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac384c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and resize images\n",
    "def load_images(max_size=1000):\n",
    "    \"\"\"Load, resize, and validate four overlapping images.\"\"\"\n",
    "    paths = [\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im1.jpg',\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im2.jpg',\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im3.jpg',\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im4.jpg'\n",
    "    ]\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Failed to load image: {path}\")\n",
    "        # Resize image to keep max dimension <= max_size\n",
    "        h, w = img.shape[:2]\n",
    "        scale = min(max_size / w, max_size / h, 1.0)\n",
    "        if scale < 1.0:\n",
    "            img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        images.append(img)\n",
    "    gray_images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "    \n",
    "    # Visualize input images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, img in enumerate(images, 1):\n",
    "        plt.subplot(2, 2, i)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Image {i}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Input Images')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\input_images.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return images, gray_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da45df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: SIFT feature detection\n",
    "def detect_sift_features(gray_images, contrast_threshold=0.04, edge_threshold=10):\n",
    "    \"\"\"Detect SIFT keypoints and descriptors.\"\"\"\n",
    "    sift = cv2.SIFT_create(contrastThreshold=contrast_threshold, edgeThreshold=edge_threshold)\n",
    "    keypoints_list, descriptors_list, keypoints_images = [], [], []\n",
    "    for i, gray_img in enumerate(gray_images):\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "        keypoints_list.append(keypoints)\n",
    "        descriptors_list.append(descriptors)\n",
    "        keypoint_img = cv2.drawKeypoints(\n",
    "            gray_img, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "        )\n",
    "        keypoints_images.append(keypoint_img)\n",
    "        print(f\"Image {i+1}: Detected {len(keypoints)} keypoints\")\n",
    "    \n",
    "    # Visualize keypoints\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, img in enumerate(keypoints_images, 1):\n",
    "        plt.subplot(2, 2, i)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Image {i} Keypoints')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('SIFT Keypoints')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\sift_keypoints.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return keypoints_list, descriptors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822562f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature matching\n",
    "def match_features(keypoints_list, descriptors_list, ratio_threshold=0.75):\n",
    "    \"\"\"Match SIFT keypoints between consecutive image pairs.\"\"\"\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches_list = []\n",
    "    for i in range(len(descriptors_list) - 1):\n",
    "        matches = matcher.knnMatch(descriptors_list[i], descriptors_list[i + 1], k=2)\n",
    "        good_matches = [m for m, n in matches if m.distance < ratio_threshold * n.distance]\n",
    "        matches_list.append(good_matches)\n",
    "        print(f\"Image {i+1} to Image {i+2}: {len(good_matches)} good matches\")\n",
    "    \n",
    "    # Visualize matches\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(len(matches_list)):\n",
    "        match_img = cv2.drawMatches(\n",
    "            images[i], keypoints_list[i],\n",
    "            images[i + 1], keypoints_list[i + 1],\n",
    "            matches_list[i], None,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        plt.subplot(len(matches_list), 1, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Matches: Image {i+1} to Image {i+2}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\matched_keypoints.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42dab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Homography estimation\n",
    "def estimate_homography(keypoints_list, matches_list, ransac_reproj_threshold=5.0):\n",
    "    \"\"\"Estimate homography matrices between consecutive image pairs.\"\"\"\n",
    "    homographies = []\n",
    "    inlier_masks = []\n",
    "    for i, matches in enumerate(matches_list):\n",
    "        src_pts = np.float32([keypoints_list[i][m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints_list[i + 1][m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, ransac_reproj_threshold)\n",
    "        if H is None:\n",
    "            print(f\"Image {i+1} to Image {i+2}: Homography estimation failed.\")\n",
    "            homographies.append(None)\n",
    "            inlier_masks.append(None)\n",
    "        else:\n",
    "            inliers = np.sum(mask)\n",
    "            print(f\"Image {i+1} to Image {i+2}: {inliers} inliers out of {len(matches)} matches\")\n",
    "            homographies.append(H)\n",
    "            inlier_masks.append(mask.ravel().tolist())\n",
    "    \n",
    "    # Visualize inlier matches\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(len(matches_list)):\n",
    "        inlier_matches = [m for j, m in enumerate(matches_list[i]) if inlier_masks[i] and inlier_masks[i][j]]\n",
    "        match_img = cv2.drawMatches(\n",
    "            images[i], keypoints_list[i],\n",
    "            images[i + 1], keypoints_list[i + 1],\n",
    "            inlier_matches, None,\n",
    "            matchColor=(0, 255, 0),\n",
    "            singlePointColor=None,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        plt.subplot(len(matches_list), 1, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Inlier Matches: Image {i+1} to Image {i+2}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\inlier_matches.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return homographies, inlier_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Warping and blending\n",
    "def warp_and_blend_images(images, homographies, reference_idx=1, max_canvas_size=10000):\n",
    "    \"\"\"Warp images using homographies and blend them into a panorama with canvas size limit.\"\"\"\n",
    "    h, w = images[reference_idx].shape[:2]\n",
    "    corners = []\n",
    "    for i in range(len(images)):\n",
    "        H = np.eye(3)\n",
    "        if i < reference_idx:\n",
    "            for j in range(i, reference_idx):\n",
    "                H = np.dot(homographies[j], H)\n",
    "        elif i > reference_idx:\n",
    "            for j in range(reference_idx, i):\n",
    "                H = np.dot(np.linalg.inv(homographies[j]), H)\n",
    "        corners_i = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        warped_corners = cv2.perspectiveTransform(corners_i, H)\n",
    "        corners.append(warped_corners)\n",
    "    \n",
    "    # Compute canvas size with limits\n",
    "    all_corners = np.concatenate(corners, axis=0)\n",
    "    x_min, y_min = np.int32(all_corners.min(axis=0).ravel())\n",
    "    x_max, y_max = np.int32(all_corners.max(axis=0).ravel())\n",
    "    panorama_width = min(x_max - x_min, max_canvas_size)\n",
    "    panorama_height = min(y_max - y_min, max_canvas_size)\n",
    "    \n",
    "    # Adjust translation to fit within canvas\n",
    "    translation = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]], dtype=np.float32)\n",
    "    \n",
    "    # Scale homographies if canvas exceeds max size\n",
    "    scale = min(max_canvas_size / panorama_width, max_canvas_size / panorama_height, 1.0)\n",
    "    if scale < 1.0:\n",
    "        scale_matrix = np.array([[scale, 0, 0], [0, scale, 0], [0, 0, 1]], dtype=np.float32)\n",
    "        translation = np.dot(scale_matrix, translation)\n",
    "        panorama_width = int(panorama_width * scale)\n",
    "        panorama_height = int(panorama_height * scale)\n",
    "    \n",
    "    # Warp images\n",
    "    warped_images = []\n",
    "    for i in range(len(images)):\n",
    "        H = np.eye(3)\n",
    "        if i < reference_idx:\n",
    "            for j in range(i, reference_idx):\n",
    "                H = np.dot(homographies[j], H)\n",
    "        elif i > reference_idx:\n",
    "            for j in range(reference_idx, i):\n",
    "                H = np.dot(np.linalg.inv(homographies[j]), H)\n",
    "        H = np.dot(translation, H)\n",
    "        warped_img = cv2.warpPerspective(\n",
    "            images[i], H, (panorama_width, panorama_height), flags=cv2.INTER_LINEAR\n",
    "        )\n",
    "        warped_images.append(warped_img)\n",
    "    \n",
    "    # Blend images\n",
    "    panorama = np.zeros((panorama_height, panorama_width, 3), dtype=np.float32)\n",
    "    weight_sum = np.zeros((panorama_height, panorama_width), dtype=np.float32)\n",
    "    for i, warped_img in enumerate(warped_images):\n",
    "        mask = np.any(warped_img > 0, axis=2).astype(np.float32)\n",
    "        panorama += warped_img * mask[:, :, np.newaxis]\n",
    "        weight_sum += mask\n",
    "    weight_sum[weight_sum == 0] = 1\n",
    "    panorama /= weight_sum[:, :, np.newaxis]\n",
    "    panorama = np.clip(panorama, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Visualize and export panorama\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Final Panorama')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\panorama.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "try:\n",
    "    # Load and resize images\n",
    "    images, gray_images = load_images(max_size=1000)\n",
    "    \n",
    "    # SIFT feature detection\n",
    "    keypoints_list, descriptors_list = detect_sift_features(gray_images)\n",
    "    \n",
    "    # Feature matching\n",
    "    matches_list = match_features(keypoints_list, descriptors_list)\n",
    "    \n",
    "    # Homography estimation\n",
    "    homographies, inlier_masks = estimate_homography(keypoints_list, matches_list)\n",
    "    \n",
    "    # Warping and blending\n",
    "    panorama = warp_and_blend_images(images, homographies)\n",
    "    \n",
    "    print(\"All outputs generated successfully. Check saved PNG files for report.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e89b7",
   "metadata": {},
   "source": [
    "ORB + RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load and resize images\n",
    "def load_images(max_size=1000):\n",
    "    \"\"\"Load, resize, and validate four overlapping images.\"\"\"\n",
    "    paths = [\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im1.jpg',\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im2.jpg',\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im3.jpg',\n",
    "        r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\input\\part_c\\im4.jpg'\n",
    "    ]\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Failed to load image: {path}\")\n",
    "        # Resize image to keep max dimension <= max_size\n",
    "        h, w = img.shape[:2]\n",
    "        scale = min(max_size / w, max_size / h, 1.0)\n",
    "        if scale < 1.0:\n",
    "            img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        images.append(img)\n",
    "    gray_images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "    \n",
    "    # Visualize input images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, img in enumerate(images, 1):\n",
    "        plt.subplot(2, 2, i)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Image {i}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Input Images (ORB)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\orb_input_images.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return images, gray_images\n",
    "\n",
    "# Step 2: ORB feature detection\n",
    "def detect_orb_features(gray_images, nfeatures=500):\n",
    "    \"\"\"Detect ORB keypoints and descriptors.\"\"\"\n",
    "    orb = cv2.ORB_create(nfeatures=nfeatures)\n",
    "    keypoints_list, descriptors_list, keypoints_images = [], [], []\n",
    "    for i, gray_img in enumerate(gray_images):\n",
    "        keypoints, descriptors = orb.detectAndCompute(gray_img, None)\n",
    "        keypoints_list.append(keypoints)\n",
    "        descriptors_list.append(descriptors)\n",
    "        keypoint_img = cv2.drawKeypoints(\n",
    "            gray_img, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "        )\n",
    "        keypoints_images.append(keypoint_img)\n",
    "        print(f\"Image {i+1}: Detected {len(keypoints)} keypoints\")\n",
    "    \n",
    "    # Visualize keypoints\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, img in enumerate(keypoints_images, 1):\n",
    "        plt.subplot(2, 2, i)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f'Image {i} Keypoints (ORB)')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('ORB Keypoints')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\orb_keypoints.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return keypoints_list, descriptors_list\n",
    "\n",
    "# Step 3: Feature matching\n",
    "def match_features(keypoints_list, descriptors_list, ratio_threshold=0.75):\n",
    "    \"\"\"Match ORB keypoints between consecutive image pairs.\"\"\"\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    matches_list = []\n",
    "    for i in range(len(descriptors_list) - 1):\n",
    "        if descriptors_list[i] is None or descriptors_list[i+1] is None:\n",
    "            print(f\"Image {i+1} to Image {i+2}: No descriptors available\")\n",
    "            matches_list.append([])\n",
    "            continue\n",
    "        matches = matcher.knnMatch(descriptors_list[i], descriptors_list[i + 1], k=2)\n",
    "        good_matches = [m for m, n in matches if m.distance < ratio_threshold * n.distance]\n",
    "        matches_list.append(good_matches)\n",
    "        print(f\"Image {i+1} to Image {i+2}: {len(good_matches)} good matches\")\n",
    "    \n",
    "    # Visualize matches\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(len(matches_list)):\n",
    "        match_img = cv2.drawMatches(\n",
    "            images[i], keypoints_list[i],\n",
    "            images[i + 1], keypoints_list[i + 1],\n",
    "            matches_list[i], None,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        plt.subplot(len(matches_list), 1, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Matches: Image {i+1} to Image {i+2} (ORB)')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\orb_matched_keypoints.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return matches_list\n",
    "\n",
    "# Step 4: Homography estimation\n",
    "def estimate_homography(keypoints_list, matches_list, ransac_reproj_threshold=5.0):\n",
    "    \"\"\"Estimate homography matrices between consecutive image pairs.\"\"\"\n",
    "    homographies = []\n",
    "    inlier_masks = []\n",
    "    for i, matches in enumerate(matches_list):\n",
    "        if len(matches) < 4:\n",
    "            print(f\"Image {i+1} to Image {i+2}: Insufficient matches ({len(matches)})\")\n",
    "            homographies.append(None)\n",
    "            inlier_masks.append(None)\n",
    "            continue\n",
    "        src_pts = np.float32([keypoints_list[i][m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints_list[i + 1][m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, ransac_reproj_threshold)\n",
    "        if H is None:\n",
    "            print(f\"Image {i+1} to Image {i+2}: Homography estimation failed\")\n",
    "            homographies.append(None)\n",
    "            inlier_masks.append(None)\n",
    "        else:\n",
    "            inliers = np.sum(mask)\n",
    "            print(f\"Image {i+1} to Image {i+2}: {inliers} inliers out of {len(matches)} matches\")\n",
    "            homographies.append(H)\n",
    "            inlier_masks.append(mask.ravel().tolist())\n",
    "    \n",
    "    # Visualize inlier matches\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(len(matches_list)):\n",
    "        if inlier_masks[i] is None:\n",
    "            continue\n",
    "        inlier_matches = [m for j, m in enumerate(matches_list[i]) if inlier_masks[i][j]]\n",
    "        match_img = cv2.drawMatches(\n",
    "            images[i], keypoints_list[i],\n",
    "            images[i + 1], keypoints_list[i + 1],\n",
    "            inlier_matches, None,\n",
    "            matchColor=(0, 255, 0),\n",
    "            singlePointColor=None,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        plt.subplot(len(matches_list), 1, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Inlier Matches: Image {i+1} to Image {i+2} (ORB)')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\orb_inlier_matches.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return homographies, inlier_masks\n",
    "\n",
    "# Step 5: Warping and blending\n",
    "def warp_and_blend_images(images, homographies, reference_idx=1, max_canvas_size=10000):\n",
    "    \"\"\"Warp images using homographies and blend them into a panorama with canvas size limit.\"\"\"\n",
    "    h, w = images[reference_idx].shape[:2]\n",
    "    corners = []\n",
    "    valid_homographies = []\n",
    "    for i in range(len(images)):\n",
    "        H = np.eye(3)\n",
    "        valid = True\n",
    "        if i < reference_idx:\n",
    "            for j in range(i, reference_idx):\n",
    "                if homographies[j] is None:\n",
    "                    valid = False\n",
    "                    break\n",
    "                H = np.dot(homographies[j], H)\n",
    "        elif i > reference_idx:\n",
    "            for j in range(reference_idx, i):\n",
    "                if homographies[j] is None:\n",
    "                    valid = False\n",
    "                    break\n",
    "                H = np.dot(np.linalg.inv(homographies[j]), H)\n",
    "        if not valid:\n",
    "            corners.append(None)\n",
    "            continue\n",
    "        corners_i = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        warped_corners = cv2.perspectiveTransform(corners_i, H)\n",
    "        corners.append(warped_corners)\n",
    "        valid_homographies.append(H)\n",
    "    \n",
    "    # Compute canvas size with limits\n",
    "    valid_corners = [c for c in corners if c is not None]\n",
    "    if not valid_corners:\n",
    "        raise ValueError(\"No valid homographies for warping\")\n",
    "    all_corners = np.concatenate(valid_corners, axis=0)\n",
    "    x_min, y_min = np.int32(all_corners.min(axis=0).ravel())\n",
    "    x_max, y_max = np.int32(all_corners.max(axis=0).ravel())\n",
    "    panorama_width = min(x_max - x_min, max_canvas_size)\n",
    "    panorama_height = min(y_max - y_min, max_canvas_size)\n",
    "    \n",
    "    # Adjust translation to fit within canvas\n",
    "    translation = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]], dtype=np.float32)\n",
    "    \n",
    "    # Scale homographies if canvas exceeds max size\n",
    "    scale = min(max_canvas_size / panorama_width, max_canvas_size / panorama_height, 1.0)\n",
    "    if scale < 1.0:\n",
    "        scale_matrix = np.array([[scale, 0, 0], [0, scale, 0], [0, 0, 1]], dtype=np.float32)\n",
    "        translation = np.dot(scale_matrix, translation)\n",
    "        panorama_width = int(panorama_width * scale)\n",
    "        panorama_height = int(panorama_height * scale)\n",
    "    \n",
    "    # Warp images\n",
    "    warped_images = []\n",
    "    for i in range(len(images)):\n",
    "        if corners[i] is None:\n",
    "            continue\n",
    "        H = valid_homographies[i] if i < len(valid_homographies) else np.eye(3)\n",
    "        H = np.dot(translation, H)\n",
    "        warped_img = cv2.warpPerspective(\n",
    "            images[i], H, (panorama_width, panorama_height), flags=cv2.INTER_LINEAR\n",
    "        )\n",
    "        warped_images.append(warped_img)\n",
    "    \n",
    "    # Blend images\n",
    "    panorama = np.zeros((panorama_height, panorama_width, 3), dtype=np.float32)\n",
    "    weight_sum = np.zeros((panorama_height, panorama_width), dtype=np.float32)\n",
    "    for warped_img in warped_images:\n",
    "        mask = np.any(warped_img > 0, axis=2).astype(np.float32)\n",
    "        panorama += warped_img * mask[:, :, np.newaxis]\n",
    "        weight_sum += mask\n",
    "    weight_sum[weight_sum == 0] = 1\n",
    "    panorama /= weight_sum[:, :, np.newaxis]\n",
    "    panorama = np.clip(panorama, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Visualize and export panorama\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(cv2.cvtColor(panorama, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Final Panorama (ORB)')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r'D:\\University\\Computer_vision\\CV\\Computer_vision_assigment\\Midterm\\data\\output\\part_c\\orb_panorama.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return panorama\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    # Load and resize images\n",
    "    images, gray_images = load_images(max_size=1000)\n",
    "    \n",
    "    # ORB feature detection\n",
    "    keypoints_list, descriptors_list = detect_orb_features(gray_images, nfeatures=500)\n",
    "    \n",
    "    # Feature matching\n",
    "    matches_list = match_features(keypoints_list, descriptors_list, ratio_threshold=0.75)\n",
    "    \n",
    "    # Homography estimation\n",
    "    homographies, inlier_masks = estimate_homography(keypoints_list, matches_list, ransac_reproj_threshold=5.0)\n",
    "    \n",
    "    # Warping and blending\n",
    "    panorama = warp_and_blend_images(images, homographies, reference_idx=1)\n",
    "    \n",
    "    print(\"All ORB outputs generated successfully. Check saved PNG files for comparison.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e5281",
   "metadata": {},
   "source": [
    "SURF + RANSAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd1fa3",
   "metadata": {},
   "source": [
    "SURF + RANSAC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
